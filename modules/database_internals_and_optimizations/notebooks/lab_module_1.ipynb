{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9d7739",
   "metadata": {},
   "source": [
    "# Module 1: The Disk is the Enemy\n",
    "**Goal**: Shatter the illusion that data access is instant. We will prove that Disk I/O is the bottleneck and understand why \"Full Table Scans\" (Sequential) often beat \"Index Lookups\" (Random) on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742ba6d",
   "metadata": {},
   "source": [
    "## 1.0 The Laboratory Setup\n",
    "First, let's load our tools and define the location of our laboratory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e63f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "import psycopg2\n",
    "\n",
    "# Configure visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# The \"God Script\" Data Locations\n",
    "DATA_DIR = \"../data/\"\n",
    "USERS_FILE = os.path.join(DATA_DIR, \"users.csv\")\n",
    "ORDERS_SORTED = os.path.join(DATA_DIR, \"orders_sorted.csv\")\n",
    "ORDERS_SHUFFLED = os.path.join(DATA_DIR, \"orders_shuffled.csv\")\n",
    "\n",
    "# Verify data exists\n",
    "print(f\"Checking environment...\")\n",
    "for f in [USERS_FILE, ORDERS_SORTED, ORDERS_SHUFFLED]:\n",
    "    if os.path.exists(f):\n",
    "        size_mb = os.path.getsize(f) / (1024 * 1024)\n",
    "        print(f\"Found {os.path.basename(f)}: {size_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"MISSING: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe80ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba135f",
   "metadata": {},
   "source": [
    "## 1.1 The Hierarchy of Speed: Light vs. The Snail\n",
    "**The Hypothesis**: We often treat memory (RAM) and Disk (SSD/HDD) as simply \"storage.\" But physically, they are different worlds. RAM sits on the motherboard next to the CPU. Disk sits across a bus, far away.\n",
    "\n",
    "We will compare:\n",
    "1. CPU/RAM: Summing 10 million numbers already in memory.\n",
    "2. Disk: Reading those same numbers from a file on disk.\n",
    "\n",
    "**The Experiment**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40038032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Create a dummy array in RAM (10 million integers)\n",
    "# This simulates data already loaded in the Buffer Pool\n",
    "data_ram = np.random.randint(0, 100, 10_000_000)\n",
    "\n",
    "# 2. Write this to disk so we can read it back\n",
    "# This simulates data sitting in \"Cold Storage\"\n",
    "np.save(os.path.join(DATA_DIR, \"temp_experiment_1.npy\"), data_ram)\n",
    "disk_file_path = os.path.join(DATA_DIR, \"temp_experiment_1.npy\")\n",
    "\n",
    "def run_cpu_test():\n",
    "    start = time.time()\n",
    "    _ = data_ram.sum()\n",
    "    return time.time() - start\n",
    "\n",
    "def run_disk_test():\n",
    "    start = time.time()\n",
    "    # We must open the file, read bytes, and parse them\n",
    "    _ = np.load(disk_file_path)\n",
    "    return time.time() - start\n",
    "\n",
    "# Run 5 iterations to average\n",
    "cpu_times = [run_cpu_test() for _ in range(5)]\n",
    "disk_times = [run_disk_test() for _ in range(5)]\n",
    "\n",
    "avg_cpu = sum(cpu_times) / len(cpu_times)\n",
    "avg_disk = sum(disk_times) / len(disk_times)\n",
    "\n",
    "print(f\"RAM Latency:  {avg_cpu:.6f} seconds\")\n",
    "print(f\"Disk Latency: {avg_disk:.6f} seconds\")\n",
    "print(f\"Factor: Disk was {avg_disk / avg_cpu:.0f}x slower\")\n",
    "\n",
    "# Clean up\n",
    "os.remove(disk_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146e9d4",
   "metadata": {},
   "source": [
    "**The Visualization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['RAM Access', 'Disk Access']\n",
    "times = [avg_cpu, avg_disk]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# We use log scale because the difference is often too massive to see on a linear scale\n",
    "plt.bar(labels, times, color=['#4c72b0', '#c44e52'])\n",
    "plt.ylabel('Time (Seconds)')\n",
    "plt.title('The I/O Cliff: RAM vs Disk Latency')\n",
    "plt.yscale('log') # Log scale is crucial here!\n",
    "for i, v in enumerate(times):\n",
    "    plt.text(i, v, f\"{v:.4f}s\", ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8654ed6",
   "metadata": {},
   "source": [
    "**The Physics**: Why the massive gap?\n",
    "1. **Distance**: Electricity travels fast, but the CPU-RAM bus is optimized for nanoseconds. The Disk bus (SATA/NVMe) is optimized for milliseconds (or microseconds on fast NVMe).\n",
    "2. **Protocol Overhead**: Reading from disk involves the Operating System (Kernel), Filesystem drivers, and hardware controllers. Reading from RAM is a direct CPU instruction. This is why Databases fight so hard to keep the \"Working Set\" in the Buffer Pool (RAM).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667f8b2",
   "metadata": {},
   "source": [
    "## 1.2 The \"Minimum Order\" Rule (Pages & Blocks)\n",
    "**The Hypothesis**: If reading a file is slow, surely reading just 1 byte is much faster than reading 8 KB (8192 bytes), right? It's 8000 times less data!\n",
    "\n",
    "**The Experiment**: We will use Python's raw file handler to read from `orders_sorted.csv`.\n",
    "1. Read 1 Byte, 10,000 times.\n",
    "2. Read 8 KB (Standard Page Size), 10,000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40610b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bytes(chunk_size, iterations=1000):\n",
    "    start = time.time()\n",
    "    with open(ORDERS_SORTED, 'rb') as f:\n",
    "        for _ in range(iterations):\n",
    "            # Seek to a random position to prevent OS readahead caching from cheating too much\n",
    "            # We want to simulate distinct fetch requests\n",
    "            pos = random.randint(0, os.path.getsize(ORDERS_SORTED) - chunk_size)\n",
    "            f.seek(pos)\n",
    "            _ = f.read(chunk_size)\n",
    "    return time.time() - start\n",
    "\n",
    "# Run the test\n",
    "time_1_byte = read_bytes(chunk_size=1)\n",
    "time_8_kb   = read_bytes(chunk_size=8192)\n",
    "\n",
    "print(f\"Time to read 1 Byte  (x1000): {time_1_byte:.4f} s\")\n",
    "print(f\"Time to read 8 KB    (x1000): {time_8_kb:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfd006",
   "metadata": {},
   "source": [
    "**The Visualization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e19a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['1 Byte', '8 KB (Page)'], [time_1_byte, time_8_kb], color=['gray', 'green'])\n",
    "plt.title('The Cost of I/O is the TRIP, not the LUGGAGE')\n",
    "plt.ylabel('Total Time (Seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8f365",
   "metadata": {},
   "source": [
    "**The Physics**: You should see that the times are **nearly identical**, despite one payload being 8000x larger.\n",
    "- **The Page**: Disks and Operating Systems do not speak in \"bytes.\" They speak in \"Pages\" (usually 4KB or 8KB) or \"Blocks.\"\n",
    "- **The Overhead**: When you ask for 1 byte, the OS fetches the entire 4KB/8KB page into memory, then gives you the 1 byte you asked for.\n",
    "- **Lesson**: In Database design, fetching a single row is just as expensive as fetching the whole page of rows surrounding it. This drives the philosophy of \"**Data Locality**\"—packing related data into the same page.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8d27f",
   "metadata": {},
   "source": [
    "## 1.3 Sequential vs. Random Access (The Seek Tax)\n",
    "**The Hypothesis**: We have `orders_sorted.csv` (physically sorted by date) and `orders_shuffled.csv` (random order).\n",
    "- **Sequential Read**: The disk head (or flash controller) reads continuous blocks.\n",
    "- **Random Seek**: The disk must \"jump\" to new locations for every read.\n",
    "\n",
    "**The Experiment**: We will simulate reading 50MB of data.\n",
    "- **Sequential**: Read 50MB continuously from one file.\n",
    "- **Random**: Read 50MB by jumping around (seeking) and reading small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_TOTAL_MB = 50\n",
    "CHUNK_SIZE = 8192 # 8KB\n",
    "ITERATIONS = int((READ_TOTAL_MB * 1024 * 1024) / CHUNK_SIZE)\n",
    "\n",
    "def test_sequential():\n",
    "    start = time.time()\n",
    "    with open(ORDERS_SORTED, 'rb') as f:\n",
    "        # Just read straight through\n",
    "        for _ in range(ITERATIONS):\n",
    "            _ = f.read(CHUNK_SIZE)\n",
    "    return time.time() - start\n",
    "\n",
    "def test_random():\n",
    "    file_size = os.path.getsize(ORDERS_SHUFFLED)\n",
    "    start = time.time()\n",
    "    with open(ORDERS_SHUFFLED, 'rb') as f:\n",
    "        # Jump around for every read\n",
    "        for _ in range(ITERATIONS):\n",
    "            pos = random.randint(0, file_size - CHUNK_SIZE)\n",
    "            f.seek(pos)\n",
    "            _ = f.read(CHUNK_SIZE)\n",
    "    return time.time() - start\n",
    "\n",
    "seq_time = test_sequential()\n",
    "rand_time = test_random()\n",
    "\n",
    "print(f\"Sequential Read (50MB): {seq_time:.4f} s\")\n",
    "print(f\"Random Seek     (50MB): {rand_time:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927cf64",
   "metadata": {},
   "source": [
    "**The Visualization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Sequential Scan', 'Random Seek'], [seq_time, rand_time], color=['#55a868', '#c44e52'])\n",
    "plt.title('Throughput Killer: Scanning vs. Seeking')\n",
    "plt.ylabel('Time to read 50MB (Seconds)')\n",
    "\n",
    "# Calculate Throughput\n",
    "seq_mb_s = READ_TOTAL_MB / seq_time\n",
    "rand_mb_s = READ_TOTAL_MB / rand_time\n",
    "\n",
    "# Annotate with speed\n",
    "plt.text(0, seq_time, f\"{seq_mb_s:.0f} MB/s\", ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "plt.text(1, rand_time, f\"{rand_mb_s:.0f} MB/s\", ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c51129",
   "metadata": {},
   "source": [
    "**The Physics**:\n",
    "- **Mechanical (HDD)**: Random access requires moving the physical arm (Seek Time) and waiting for the platter to rotate (Rotational Latency). This is physical movement—it takes forever.\n",
    "- **Solid State (SSD)**: While SSDs have no moving parts, random I/O still stresses the controller's \"IOPS\" (Input/Output Operations Per Second) limit and prevents the OS from doing \"Prefetching\" (predicting what you need next).\n",
    "- **Database Implication**: This is why Full Table Scans (Sequential) are often preferred over Index Lookups if you need more than 5-10% of the table. The index forces random seeking (jumping from index to table heap), which destroys throughput.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c26035",
   "metadata": {},
   "source": [
    "## Module Summary\n",
    "1. **Disk is slow**: Avoid going to disk whenever possible (Cache/RAM is King).\n",
    "2. **I/O is block-based**: Never read 1 byte. Read the whole page.\n",
    "3. **Seeking is expensive**: Sequential access is high throughput; Random access is low throughput."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
